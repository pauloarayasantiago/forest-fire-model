{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "Best Parameters: {'subsample': 0.7000000000000001, 'n_estimators': 250, 'max_depth': 9, 'learning_rate': 0.07105263157894737, 'gamma': 0.16666666666666666, 'colsample_bytree': 0.1}\n",
      "Test RMSE: 0.8262663352228432\n",
      "Test MAE: 0.6717272779675366\n",
      "Test R²: 0.06358847756388497\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "Random Forest Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 265}\n",
      "Random Forest Test RMSE: 0.7933749545155441\n",
      "Random Forest Test MAE: 0.6531715111970238\n",
      "Random Forest Test R²: 0.1366565374854688\n",
      "Stacking Regressor Test RMSE: 0.8228626495970558\n",
      "Stacking Regressor Test MAE: 0.6642860686230873\n",
      "Stacking Regressor Test R²: 0.07128741334933386\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'forestfires.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove the specified columns\n",
    "df.drop(columns=['rain', 'X', 'Y', 'day'], inplace=True)\n",
    "\n",
    "# Convert months to a binary summer category\n",
    "def is_summer(month):\n",
    "    return int(month in ['jun', 'jul', 'aug'])\n",
    "\n",
    "df['is_summer'] = df['month'].apply(is_summer)\n",
    "df.drop(columns='month', inplace=True)\n",
    "\n",
    "# Function to remove outliers using IQR method\n",
    "def remove_outliers_iqr(df, columns):\n",
    "    Q1 = df[columns].quantile(0.25)\n",
    "    Q3 = df[columns].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[~((df[columns] < lower_bound) | (df[columns] > upper_bound)).any(axis=1)]\n",
    "\n",
    "# Remove outliers\n",
    "numeric_features = ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'area']\n",
    "df = remove_outliers_iqr(df, numeric_features)\n",
    "\n",
    "# Apply log transformation to the target variable\n",
    "df['log_area'] = np.log1p(df['area'])  # log1p is used to handle log(0)\n",
    "\n",
    "# Create new features\n",
    "df['temp_RH_interaction'] = df['temp'] * df['RH']\n",
    "df['wind_ISI_interaction'] = df['wind'] * df['ISI']\n",
    "\n",
    "# Generate polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(df[numeric_features[:-1]])\n",
    "poly_feature_names = [f\"poly_{i}\" for i in range(poly_features.shape[1])]\n",
    "\n",
    "# Combine polynomial features with the original data\n",
    "df_poly = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
    "df = pd.concat([df, df_poly], axis=1)\n",
    "\n",
    "# Check for and handle NaN or infinite values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop(columns=['area', 'log_area'])\n",
    "y = df['log_area']\n",
    "\n",
    "# Normalize the numeric features\n",
    "scaler = StandardScaler()\n",
    "X[numeric_features[:-1]] = scaler.fit_transform(X[numeric_features[:-1]])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Set up the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'colsample_bytree': np.linspace(0.1, 1.0, 10),\n",
    "    'gamma': np.linspace(0, 0.5, 10),\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 20),\n",
    "    'max_depth': range(3, 12),\n",
    "    'n_estimators': range(50, 300, 20),\n",
    "    'subsample': np.linspace(0.1, 1.0, 10)\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb_model, \n",
    "    param_distributions=param_grid, \n",
    "    n_iter=300,  # Increase the number of iterations\n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=1, \n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"Test RMSE: {rmse}\")\n",
    "print(f\"Test MAE: {mae}\")\n",
    "print(f\"Test R²: {r2}\")\n",
    "\n",
    "# Compare with RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_param_grid = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'max_depth': randint(3, 12),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20)\n",
    "}\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    rf_model,\n",
    "    param_distributions=rf_param_grid,\n",
    "    n_iter=300,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf_model = rf_random_search.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the RandomForest model\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest Best Parameters: {rf_random_search.best_params_}\")\n",
    "print(f\"Random Forest Test RMSE: {rmse_rf}\")\n",
    "print(f\"Random Forest Test MAE: {mae_rf}\")\n",
    "print(f\"Random Forest Test R²: {r2_rf}\")\n",
    "\n",
    "# Ensemble method (Stacking Regressor)\n",
    "estimators = [\n",
    "    ('xgb', best_xgb_model),\n",
    "    ('rf', best_rf_model)\n",
    "]\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=estimators, \n",
    "    final_estimator=LinearRegression(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "y_pred_ensemble = stacking_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble method\n",
    "mae_ensemble = mean_absolute_error(y_test, y_pred_ensemble)\n",
    "mse_ensemble = mean_squared_error(y_test, y_pred_ensemble)\n",
    "rmse_ensemble = np.sqrt(mse_ensemble)\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble)\n",
    "\n",
    "print(f\"Stacking Regressor Test RMSE: {rmse_ensemble}\")\n",
    "print(f\"Stacking Regressor Test MAE: {mae_ensemble}\")\n",
    "print(f\"Stacking Regressor Test R²: {r2_ensemble}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "forest_fires_df = pd.read_csv('forestfires.csv')\n",
    "\n",
    "# Handle missing values (if any)\n",
    "forest_fires_df = forest_fires_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'#' is not recognized as an internal or external command,\",\n",
       " 'operable program or batch file.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%!\n",
    "# Convert month to season\n",
    "def month_to_season(month):\n",
    "    if month in ['dec', 'jan', 'feb']:\n",
    "        return 'winter'\n",
    "    elif month in ['mar', 'apr', 'may']:\n",
    "        return 'spring'\n",
    "    elif month in ['jun', 'jul', 'aug']:\n",
    "        return 'summer'\n",
    "    else:\n",
    "        return 'fall'\n",
    "\n",
    "forest_fires_df['season'] = forest_fires_df['month'].apply(month_to_season)\n",
    "forest_fires_df = forest_fires_df.drop(columns=['month']) \n",
    "\n",
    "# Convert categorical features to numerical using one-hot encoding\n",
    "forest_fires_df = pd.get_dummies(forest_fires_df, columns=['season'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform the 'area' to handle skewness\n",
    "forest_fires_df['log_area'] = np.log1p(forest_fires_df['area'])\n",
    "\n",
    "# Drop unneccesary columns\n",
    "forest_fires_df = forest_fires_df.drop(columns=['day', 'area', 'rain', 'X', 'Y', 'month'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = forest_fires_df.drop(['log_area'], axis=1)\n",
    "y = forest_fires_df['log_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify continuous features for standardization\n",
    "continuous_features = ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the column transformer with standard scaler\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), continuous_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # leave the rest of the columns unchanged\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Test RMSE (XGBoost with Bayesian Optimization): 108.74972993473384\n",
      "Test MAE (XGBoost with Bayesian Optimization): 23.479641806529116\n",
      "Test R² (XGBoost with Bayesian Optimization): -0.0032865984035617135\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter space for Bayesian Optimization\n",
    "param_space_xgb = {\n",
    "    'n_estimators': (50, 200),\n",
    "    'max_depth': (2, 10),\n",
    "    'learning_rate': (0.01, 0.2, 'log-uniform'),\n",
    "    'subsample': (0.6, 1.0, 'uniform'),\n",
    "    'colsample_bytree': (0.6, 1.0, 'uniform')\n",
    "}\n",
    "\n",
    "# Bayesian Optimization for XGBoost\n",
    "bayes_search_xgb = BayesSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    search_spaces=param_space_xgb,\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bayes_search_xgb.fit(X_train, y_train)\n",
    "best_xgb_model_bayes = bayes_search_xgb.best_estimator_\n",
    "\n",
    "# Evaluate the optimized XGBoost model\n",
    "xgb_pred_bayes = best_xgb_model_bayes.predict(X_test)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "test_rmse_bayes = np.sqrt(mean_squared_error(y_test, xgb_pred_bayes))\n",
    "test_mae_bayes = mean_absolute_error(y_test, xgb_pred_bayes)\n",
    "test_r2_bayes = r2_score(y_test, xgb_pred_bayes)\n",
    "\n",
    "print(f'Test RMSE (XGBoost with Bayesian Optimization): {test_rmse_bayes}')\n",
    "print(f'Test MAE (XGBoost with Bayesian Optimization): {test_mae_bayes}')\n",
    "print(f'Test R² (XGBoost with Bayesian Optimization): {test_r2_bayes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate Feature Importance\n",
    "# feature_importances = best_model['model'].feature_importances_\n",
    "# features = X.columns\n",
    "\n",
    "# # Create a DataFrame for feature importance\n",
    "# importance_df = pd.DataFrame({\n",
    "#     'Feature': features,\n",
    "#     'Importance': feature_importances\n",
    "# }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# # Plot the feature importance\n",
    "# plt.figure(figsize=(14, 8))\n",
    "# sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "# plt.title('Feature Importance for Predicting Fire Size')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a pipeline with the preprocessor and CatBoost model\n",
    "# cat_pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('model', CatBoostRegressor(random_state=42, silent=True))\n",
    "# ])\n",
    "\n",
    "# # Define the parameter grid for CatBoost\n",
    "# cat_param_grid = {\n",
    "#     'model__iterations': [100, 200, 300],\n",
    "#     'model__depth': [3, 5, 7],\n",
    "#     'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'model__l2_leaf_reg': [1, 3, 5]\n",
    "# }\n",
    "\n",
    "# # Initialize GridSearchCV for CatBoost\n",
    "# cat_grid_search = GridSearchCV(estimator=cat_pipeline, param_grid=cat_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# # Fit the model with GridSearchCV\n",
    "# cat_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best CatBoost model parameters\n",
    "# cat_best_params = {key.replace('model__', ''): value for key, value in cat_grid_search.best_params_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define base models\n",
    "# base_models = [\n",
    "#     ('xgb', XGBRegressor(**xgb_best_params, random_state=42)),\n",
    "#     ('cat', CatBoostRegressor(**cat_best_params, random_state=42, silent=True))\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define stacking model with ElasticNet as the final estimator\n",
    "# stacking_model_en = StackingRegressor(\n",
    "#     estimators=base_models,\n",
    "#     final_estimator=ElasticNet(random_state=42)\n",
    "# )\n",
    "\n",
    "# stacking_pipeline_en = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),\n",
    "#     ('model', stacking_model_en)\n",
    "# ])\n",
    "\n",
    "# # Fit the stacking model\n",
    "# stacking_pipeline_en.fit(X_train_poly, y_train)\n",
    "\n",
    "# # Evaluate Model Performance on Test Data\n",
    "# y_test_pred_stack_en = stacking_pipeline_en.predict(X_test_poly)\n",
    "# test_rmse_stack_en = np.sqrt(mean_squared_error(y_test, y_test_pred_stack_en))\n",
    "# test_mae_stack_en = mean_absolute_error(y_test, y_test_pred_stack_en)\n",
    "# test_r2_stack_en = r2_score(y_test, y_test_pred_stack_en)\n",
    "\n",
    "# print(f'Test RMSE (Stacking with ElasticNet): {test_rmse_stack_en}')\n",
    "# print(f'Test MAE (Stacking with ElasticNet): {test_mae_stack_en}')\n",
    "# print(f'Test R² (Stacking with ElasticNet): {test_r2_stack_en}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define stacking model with Gradient Boosting as the final estimator\n",
    "# stacking_model_gb = StackingRegressor(\n",
    "#     estimators=base_models,\n",
    "#     final_estimator=GradientBoostingRegressor(random_state=42)\n",
    "# )\n",
    "\n",
    "# stacking_pipeline_gb = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),\n",
    "#     ('model', stacking_model_gb)\n",
    "# ])\n",
    "\n",
    "# # Fit the stacking model\n",
    "# stacking_pipeline_gb.fit(X_train_poly, y_train)\n",
    "\n",
    "# # Evaluate Model Performance on Test Data\n",
    "# y_test_pred_stack_gb = stacking_pipeline_gb.predict(X_test_poly)\n",
    "# test_rmse_stack_gb = np.sqrt(mean_squared_error(y_test, y_test_pred_stack_gb))\n",
    "# test_mae_stack_gb = mean_absolute_error(y_test, y_test_pred_stack_gb)\n",
    "# test_r2_stack_gb = r2_score(y_test, y_test_pred_stack_gb)\n",
    "\n",
    "# print(f'Test RMSE (Stacking with Gradient Boosting): {test_rmse_stack_gb}')\n",
    "# print(f'Test MAE (Stacking with Gradient Boosting): {test_mae_stack_gb}')\n",
    "# print(f'Test R² (Stacking with Gradient Boosting): {test_r2_stack_gb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the best models individually\n",
    "# best_xgb_model.fit(X_train, y_train)\n",
    "# best_cat_model.fit(X_train, y_train)\n",
    "\n",
    "# # Get predictions\n",
    "# xgb_pred = best_xgb_model.predict(X_test)\n",
    "# cat_pred = best_cat_model.predict(X_test)\n",
    "\n",
    "# # Weighted averaging\n",
    "# weights = [0.6, 0.4]  # Example weights, you can optimize these\n",
    "# combined_pred = (weights[0] * xgb_pred) + (weights[1] * cat_pred)\n",
    "\n",
    "# # Evaluate the combined model\n",
    "# test_rmse_combined = np.sqrt(mean_squared_error(y_test, combined_pred))\n",
    "# test_mae_combined = mean_absolute_error(y_test, combined_pred)\n",
    "# test_r2_combined = r2_score(y_test, combined_pred)\n",
    "\n",
    "# print(f'Test RMSE (Weighted Averaging): {test_rmse_combined}')\n",
    "# print(f'Test MAE (Weighted Averaging): {test_mae_combined}')\n",
    "# print(f'Test R² (Weighted Averaging): {test_r2_combined}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform Recursive Feature Elimination (RFE) with a Linear Regression model\n",
    "# rfe = RFE(estimator=LinearRegression(), n_features_to_select=10)\n",
    "# rfe.fit(X_train, y_train)\n",
    "\n",
    "# # Select the best features\n",
    "# X_train_rfe = X_train.loc[:, rfe.support_]\n",
    "# X_test_rfe = X_test.loc[:, rfe.support_]\n",
    "\n",
    "# # Train the models again with selected features\n",
    "# best_xgb_model_rfe = XGBRegressor(**xgb_best_params, random_state=42)\n",
    "# best_cat_model_rfe = CatBoostRegressor(**cat_best_params, random_state=42, silent=True)\n",
    "\n",
    "# best_xgb_model_rfe.fit(X_train_rfe, y_train)\n",
    "# best_cat_model_rfe.fit(X_train_rfe, y_train)\n",
    "\n",
    "# # Get predictions\n",
    "# xgb_pred_rfe = best_xgb_model_rfe.predict(X_test_rfe)\n",
    "# cat_pred_rfe = best_cat_model_rfe.predict(X_test_rfe)\n",
    "\n",
    "# # Weighted averaging\n",
    "# weights = [0.6, 0.4]  # Example weights, you can optimize these\n",
    "# combined_pred_rfe = (weights[0] * xgb_pred_rfe) + (weights[1] * cat_pred_rfe)\n",
    "\n",
    "# # Evaluate the combined model\n",
    "# test_rmse_combined_rfe = np.sqrt(mean_squared_error(y_test, combined_pred_rfe))\n",
    "# test_mae_combined_rfe = mean_absolute_error(y_test, combined_pred_rfe)\n",
    "# test_r2_combined_rfe = r2_score(y_test, combined_pred_rfe)\n",
    "\n",
    "# print(f'Test RMSE (Weighted Averaging with RFE): {test_rmse_combined_rfe}')\n",
    "# print(f'Test MAE (Weighted Averaging with RFE): {test_mae_combined_rfe}')\n",
    "# print(f'Test R² (Weighted Averaging with RFE): {test_r2_combined_rfe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Voting Regressor\n",
    "# voting_regressor = VotingRegressor(estimators=[\n",
    "#     ('xgb', best_xgb_model_rfe),\n",
    "#     ('cat', best_cat_model_rfe)\n",
    "# ])\n",
    "\n",
    "# # Fit the Voting Regressor\n",
    "# voting_regressor.fit(X_train_rfe, y_train)\n",
    "\n",
    "# # Get predictions\n",
    "# voting_pred = voting_regressor.predict(X_test_rfe)\n",
    "\n",
    "# # Evaluate the Voting Regressor\n",
    "# test_rmse_voting = np.sqrt(mean_squared_error(y_test, voting_pred))\n",
    "# test_mae_voting = mean_absolute_error(y_test, voting_pred)\n",
    "# test_r2_voting = r2_score(y_test, voting_pred)\n",
    "\n",
    "# print(f'Test RMSE (Voting Regressor): {test_rmse_voting}')\n",
    "# print(f'Test MAE (Voting Regressor): {test_mae_voting}')\n",
    "# print(f'Test R² (Voting Regressor): {test_r2_voting}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the parameter space for Bayesian Optimization\n",
    "# param_space_xgb = {\n",
    "#     'n_estimators': (50, 200),\n",
    "#     'max_depth': (2, 10),\n",
    "#     'learning_rate': (0.01, 0.2, 'log-uniform'),\n",
    "#     'subsample': (0.6, 1.0, 'uniform'),\n",
    "#     'colsample_bytree': (0.6, 1.0, 'uniform')\n",
    "# }\n",
    "\n",
    "# param_space_cat = {\n",
    "#     'iterations': (100, 300),\n",
    "#     'depth': (3, 7),\n",
    "#     'learning_rate': (0.01, 0.1, 'log-uniform'),\n",
    "#     'l2_leaf_reg': (1, 5)\n",
    "# }\n",
    "\n",
    "# # Bayesian Optimization for XGBoost\n",
    "# bayes_search_xgb = BayesSearchCV(\n",
    "#     estimator=XGBRegressor(random_state=42),\n",
    "#     search_spaces=param_space_xgb,\n",
    "#     n_iter=50,\n",
    "#     cv=3,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# bayes_search_xgb.fit(X_train, y_train)\n",
    "# best_xgb_model_bayes = bayes_search_xgb.best_estimator_\n",
    "\n",
    "# # Bayesian Optimization for CatBoost\n",
    "# bayes_search_cat = BayesSearchCV(\n",
    "#     estimator=CatBoostRegressor(random_state=42, silent=True),\n",
    "#     search_spaces=param_space_cat,\n",
    "#     n_iter=50,\n",
    "#     cv=3,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# bayes_search_cat.fit(X_train, y_train)\n",
    "# best_cat_model_bayes = bayes_search_cat.best_estimator_\n",
    "\n",
    "# # Evaluate the optimized models\n",
    "# xgb_pred_bayes = best_xgb_model_bayes.predict(X_test)\n",
    "# cat_pred_bayes = best_cat_model_bayes.predict(X_test)\n",
    "\n",
    "# # Weighted averaging with Bayesian optimized models\n",
    "# weights_bayes = [0.6, 0.4]  # Example weights, can be optimized further\n",
    "# combined_pred_bayes = (weights_bayes[0] * xgb_pred_bayes) + (weights_bayes[1] * cat_pred_bayes)\n",
    "\n",
    "# # Evaluate the combined model with Bayesian optimization\n",
    "# test_rmse_combined_bayes = np.sqrt(mean_squared_error(y_test, combined_pred_bayes))\n",
    "# test_mae_combined_bayes = mean_absolute_error(y_test, combined_pred_bayes)\n",
    "# test_r2_combined_bayes = r2_score(y_test, combined_pred_bayes)\n",
    "\n",
    "# print(f'Test RMSE (Weighted Averaging with Bayesian Optimization): {test_rmse_combined_bayes}')\n",
    "# print(f'Test MAE (Weighted Averaging with Bayesian Optimization): {test_mae_combined_bayes}')\n",
    "# print(f'Test R² (Weighted Averaging with Bayesian Optimization): {test_r2_combined_bayes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the parameter grid for hyperparameter tuning\n",
    "# param_grid = {\n",
    "#     'model__n_estimators': [300, 500, 800],\n",
    "#     'model__max_depth': [None, 5, 10, 15],\n",
    "#     'model__min_samples_split': [10, 15, 18],\n",
    "#     'model__min_samples_leaf': [4, 6, 8]\n",
    "# }\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# # Fit the model with GridSearchCV\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best model\n",
    "# best_model = grid_search.best_estimator_\n",
    "# # Best parameters\n",
    "# print(f'Best Parameters: {grid_search.best_params_}')\n",
    "\n",
    "# # Evaluate Model Performance on Training Data\n",
    "# y_train_pred = best_model.predict(X_train)\n",
    "# train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "# train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "# train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# print(f'Training RMSE: {train_rmse}')\n",
    "# print(f'Training MAE: {train_mae}')\n",
    "# print(f'Training R²: {train_r2}')\n",
    "\n",
    "# # Evaluate Model Performance on Test Data\n",
    "# y_test_pred = best_model.predict(X_test)\n",
    "# test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "# test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "# test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# print(f'Test RMSE: {test_rmse}')\n",
    "# print(f'Test MAE: {test_mae}')\n",
    "# print(f'Test R²: {test_r2}')\n",
    "\n",
    "# # Cross-Validation\n",
    "# cv_rmse_scores = cross_val_score(grid_search.best_estimator_, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "# cv_rmse = -cv_rmse_scores.mean()\n",
    "# print(f'Cross-validated RMSE: {cv_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the parameter distribution for randomized search\n",
    "# param_dist = {\n",
    "#     'model__n_estimators': randint(100, 1000),\n",
    "#     'model__max_depth': randint(3, 30),\n",
    "#     'model__min_samples_split': randint(2, 20),\n",
    "#     'model__min_samples_leaf': randint(1, 20)\n",
    "# }\n",
    "\n",
    "# # Initialize RandomizedSearchCV\n",
    "# random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_dist, n_iter=50, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "\n",
    "# # Fit the model with RandomizedSearchCV\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best model\n",
    "# best_model_random = random_search.best_estimator_\n",
    "\n",
    "# # Evaluate Model Performance on Test Data\n",
    "# y_test_pred_random = best_model_random.predict(X_test)\n",
    "# test_rmse_random = np.sqrt(mean_squared_error(y_test, y_test_pred_random))\n",
    "# test_mae_random = mean_absolute_error(y_test, y_test_pred_random)\n",
    "# test_r2_random = r2_score(y_test, y_test_pred_random)\n",
    "\n",
    "# print(f'Test RMSE (RandomizedSearchCV): {test_rmse_random}')\n",
    "# print(f'Test MAE (RandomizedSearchCV): {test_mae_random}')\n",
    "# print(f'Test R² (RandomizedSearchCV): {test_r2_random}')\n",
    "# print(f'Best Parameters (RandomizedSearchCV): {random_search.best_params_}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
